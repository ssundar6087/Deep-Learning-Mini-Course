{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1MeWh78fXU0GbNwbw2uTJySmfvw1KWjKq","timestamp":1665103902452},{"file_id":"1pwiOBgRVAgW7KGVFdJWdTTamlQ7bfUXe","timestamp":1665103747612}],"collapsed_sections":[],"authorship_tag":"ABX9TyMELXe7A7kVEKUcbI1urAFF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/ssundar6087/Deep-Learning-Mini-Course/blob/main/Keras/DL_Minicourse_Keras_Day_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"],"metadata":{"id":"VeG4NPQjtl_V"}},{"cell_type":"markdown","source":["# Fun With Tensors\n","Before we train a neural net and make it great, we need to understand how to manipulate tensors. Let's start ðŸ˜€"],"metadata":{"id":"e--Ti2Ov8GTm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJmKqClAQ4x9"},"outputs":[],"source":["# Imports\n","import tensorflow as tf\n","import numpy as np"]},{"cell_type":"markdown","source":["## Numpy to Tensor and Back\n","You can convert a numpy array to a tensor and back to a numpy array as shown below."],"metadata":{"id":"ZLch75HPMo-y"}},{"cell_type":"code","source":["my_arr = np.random.random(size=(2,3))\n","\n","my_tensor = tf.convert_to_tensor(my_arr)\n","back_to_my_arr = my_tensor.numpy()\n","print(my_arr) \n","print(\"\\n\")\n","print(my_tensor) \n","print(\"\\n\")\n","print(back_to_my_arr)"],"metadata":{"id":"fPqWJPYoMoX9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Special Value Tensors\n","Below, you can see how we create random tensors, tensors with all ones and tensors with all zeros"],"metadata":{"id":"8DJHi0k2Nxu4"}},{"cell_type":"code","source":["input_shape = (2,4)\n","rand_tensor = tf.random.uniform(input_shape)\n","ones_tensor = tf.ones(input_shape)\n","zeros_tensor = tf.zeros(input_shape)\n","print(rand_tensor) \n","print(\"\\n\")\n","print(ones_tensor) \n","print(\"\\n\")\n","print(zeros_tensor)"],"metadata":{"id":"WfBj38QaNRy7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tensor Arithmetic\n","You can use tensors in a very similar fashion to numpy arrays. Pay special attention to the difference between matrix multiplication and element wise multiplication. This is often the cause for mixups while implementing things"],"metadata":{"id":"tDcL5uJmOM7-"}},{"cell_type":"code","source":["input_shape = (2, 3)\n","a = tf.random.uniform(input_shape)\n","b = tf.random.uniform(input_shape)\n","\n","print(a)\n","print(\"\\n\")\n","print(b)\n","print(\"\\n\")\n","print(a + b)\n","print(\"\\n\")\n","print(a - b)\n","print(\"\\n\")\n","print(a / b)\n","print(\"\\n\")"],"metadata":{"id":"ux1T5Gu-OJgf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Element wise multiplication: Two ways\n","print(a * b)\n","print(\"\\n\")\n","print(tf.multiply(a, b))\n","print(\"\\n\")"],"metadata":{"id":"SVdKiGGwPZG8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Matrix multiplication : Two ways\n","print(a @ tf.transpose(b))\n","print(\"\\n\")\n","print(tf.matmul(a, tf.transpose(b)))\n","print(\"\\n\")"],"metadata":{"id":"IOiijS4lPf-5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Broadcasting\n","One of the really cool features baked in is called broadcasting. When you have two tensors which are not exactly the same shape, you can still perform arithmetic operations on them. The smaller tensor is \"broadcast\" across the larger one without explicitly having to make copies. However, this only works if the following conditions hold:\n","\n","- Each tensor has at least one dimension.\n","- When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n","\n","For more details read: https://www.tensorflow.org/xla/broadcasting\n","\n","In the example below, even though tensor `b` doesn't have the same shape as `a`, it's artificially expanded without creating an explicit copy to match the shape of  `a`. "],"metadata":{"id":"lYLTzHK2P3xw"}},{"cell_type":"code","source":["a = tf.random.uniform((4, 3))\n","b = tf.random.uniform((4, 1))\n","print(a)\n","print(\"\\n\")\n","print(b)\n","print(\"\\n\")\n","print(a + b)"],"metadata":{"id":"niqPQ4EiPmdV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EiU765rNRVjI"},"execution_count":null,"outputs":[]}]}
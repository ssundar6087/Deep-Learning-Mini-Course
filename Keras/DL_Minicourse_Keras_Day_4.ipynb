{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"16vG1loKY4MurtSPfQVPWGt7OJ-VeEVrr","timestamp":1665244346476},{"file_id":"1FQIEmnOhMnl-U5AS901SAxpuMoEPsNir","timestamp":1665243989477},{"file_id":"1MeWh78fXU0GbNwbw2uTJySmfvw1KWjKq","timestamp":1665103902452},{"file_id":"1pwiOBgRVAgW7KGVFdJWdTTamlQ7bfUXe","timestamp":1665103747612}],"collapsed_sections":[],"authorship_tag":"ABX9TyM5YUlvVG+tylI/HpZ865jz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/ssundar6087/Deep-Learning-Mini-Course/blob/main/Keras/DL_Minicourse_Keras_Day_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"],"metadata":{"id":"hSPhY_1ysifT"}},{"cell_type":"markdown","source":["# Deconstructing the Model Part 1\n","Today, we'll look at the model. Note that 90% of the code will be the same as the previous notebook. Our focus is to play with the model architecture and see if we can improve results."],"metadata":{"id":"e--Ti2Ov8GTm"}},{"cell_type":"markdown","source":["# Image Classification Keras"],"metadata":{"id":"tGV5DlzgRFNK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJmKqClAQ4x9"},"outputs":[],"source":["# Imports\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"markdown","source":["## Load Dataset - CIFAR-10\n","The dataset has 10 classes with 50k training images and 10k test images"],"metadata":{"id":"UF3HfcZbRN2J"}},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n","# Normalize pixel values to be between 0 and 1\n","train_images, test_images = x_train / 255.0, x_test / 255.0\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"id":"OhzX7u6zRM8w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Show Some Images"],"metadata":{"id":"t_6t6IQz9mB0"}},{"cell_type":"code","source":["plt.figure(figsize=(8,8))\n","for i in range(16):\n","    plt.subplot(4,4,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i])\n","    plt.xlabel(classes[y_train[i][0]])\n","plt.show()"],"metadata":{"id":"GdBGdVyJ9Zoy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **YOUR EXERCISE HERE: Define the Model  ðŸ‘‡** \n","In today's exercise, you'll be creating a convolutional neural network. Previously, we flatten a 3 channel image (32 x 32 x 3) into a vector and passed that through linear layers. It's now time to spruce up the model and pass the image directly through convolutional layers.\n","\n","**Convolutions?**\n","The example below is for 2D convolutions, but generally, you have as many dimensions as you have in the input stream (images, audio, time-series, point clouds, etc.). $B$ is the batch size and $C$ is the number of channels. $dim$ is the resolution of the input which in this case is 32. Finally, $k$ is the size of the convolutional kernel.\n","\n","  - What is my input shape: $B \\times C \\times dim \\times dim$ \n","\n","  - What is my output shape: $B \\times C \\times dim' \\times dim'$\n","\n","  - Here $dim' = \\frac{(dim + 2 \\times padding - k)}{stride} + 1$\n","\n","\n","**HINT:** DO NOT SEE UNTIL YOU'VE TRIED THIS YOURSELF https://www.tensorflow.org/tutorials/images/cnn\n"],"metadata":{"id":"SMBKXZyURnyE"}},{"cell_type":"code","source":["def get_baby_thanos(input_shape, num_classes):\n","  inputs = keras.Input(shape=input_shape)\n","  # YOUR CODE HERE\n","\n","  # END CODE\n","  x = layers.Flatten()(x)\n","  x = keras.layers.Dense(100, activation='relu')(x)\n","  x = keras.layers.Dense(40, activation='relu')(x)\n","  outputs = keras.layers.Dense(num_classes)(x)\n","  return keras.Model(inputs, outputs)    "],"metadata":{"id":"CxqH8nKuRXi2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IN_FTRS = (32, 32, 3) # CIFAR-10 images are 32 x 32 and have 3 channels\n","net = get_baby_thanos(input_shape=IN_FTRS, num_classes=10)"],"metadata":{"id":"O-dwbekbT49S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net.summary()"],"metadata":{"id":"P4L8u-SMgIrN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_images.shape, test_images.shape)"],"metadata":{"id":"Z8UwzM2cPpqU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hyperparameters \n","**Note:** Use the best values from the previous exercise"],"metadata":{"id":"pp6XaQY8R90J"}},{"cell_type":"code","source":["LEARNING_RATE = 0.001\n","EPOCHS = 20\n","BATCH_SIZE = 64"],"metadata":{"id":"ecsRzyp7R_ve"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Optimizer & Loss Function\n","These two functions allow us to help baby thanos learn from his mistakes."],"metadata":{"id":"KL_5TfglTy3D"}},{"cell_type":"code","source":["criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True) # Loss Function\n","optimizer = keras.optimizers.SGD(learning_rate=LEARNING_RATE) # Optimizer "],"metadata":{"id":"Hnj1-mPITxjE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train and Evaluate the Network\n","The training and validation loops call the same set of functions over and over. Keras packages them into a nice function called `fit()` which does a lot more :)"],"metadata":{"id":"b13gdPYtUBmF"}},{"cell_type":"code","source":["net.compile(\n","    optimizer=optimizer,\n","    loss=criterion,\n","    metrics=[\"accuracy\"],\n",")"],"metadata":{"id":"_bvQQNXYV6yu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = net.fit(train_images, \n","                  y_train, \n","                  batch_size=BATCH_SIZE,\n","                  epochs=EPOCHS, \n","                  validation_data=(test_images, y_test),\n","                  )"],"metadata":{"id":"nwIv6azQOdYq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot the Loss and Accuracy of our Model"],"metadata":{"id":"ym8N-On3AABv"}},{"cell_type":"code","source":["plt.figure(figsize=(8,8))\n","plt.plot(history.history[\"loss\"], label=\"train\")\n","plt.plot(history.history[\"val_loss\"], label=\"val\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","plt.grid(\"on\")\n","plt.legend()\n","plt.title(\"Loss vs Epochs\");"],"metadata":{"id":"9S3y9L1L-WCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,8))\n","plt.plot(history.history['accuracy'], label='accuracy')\n","plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.grid(\"on\")\n","plt.legend()\n","plt.title(\"Accuracy vs Epochs\");"],"metadata":{"id":"MaZ5ZfTu_TfI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mZd5xIfiUvgz"},"execution_count":null,"outputs":[]}]}
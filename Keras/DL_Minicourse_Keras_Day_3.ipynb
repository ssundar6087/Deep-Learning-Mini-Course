{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1FQIEmnOhMnl-U5AS901SAxpuMoEPsNir","timestamp":1665243989477},{"file_id":"1MeWh78fXU0GbNwbw2uTJySmfvw1KWjKq","timestamp":1665103902452},{"file_id":"1pwiOBgRVAgW7KGVFdJWdTTamlQ7bfUXe","timestamp":1665103747612}],"collapsed_sections":[],"authorship_tag":"ABX9TyN8+ejWRuRVM8pAIUI4d3PV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/ssundar6087/Deep-Learning-Mini-Course/blob/main/Keras/DL_Minicourse_Keras_Day_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"],"metadata":{"id":"eA8T0ablsc9r"}},{"cell_type":"markdown","source":["# Deconstructing the training loop\n","Today, we'll look at the training and validation loops and play with hyperparameters. Note that 90% of the code will be the same as the previous notebook. Our focus is to play with the hyperparameters and see if we can improve results."],"metadata":{"id":"e--Ti2Ov8GTm"}},{"cell_type":"markdown","source":["# Image Classification Keras"],"metadata":{"id":"tGV5DlzgRFNK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJmKqClAQ4x9"},"outputs":[],"source":["# Imports\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow_datasets as tfds\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"markdown","source":["## Load Dataset - CIFAR-10\n","The dataset has 10 classes with 50k training images and 10k test images"],"metadata":{"id":"UF3HfcZbRN2J"}},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n","# Normalize pixel values to be between 0 and 1\n","train_images, test_images = x_train / 255.0, x_test / 255.0\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"id":"OhzX7u6zRM8w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Show Some Images"],"metadata":{"id":"t_6t6IQz9mB0"}},{"cell_type":"code","source":["plt.figure(figsize=(8,8))\n","for i in range(16):\n","    plt.subplot(4,4,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(train_images[i])\n","    plt.xlabel(classes[y_train[i][0]])\n","plt.show()"],"metadata":{"id":"GdBGdVyJ9Zoy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define our Model"],"metadata":{"id":"SMBKXZyURnyE"}},{"cell_type":"code","source":["def get_baby_thanos(input_shape, num_classes):\n","  inputs = keras.Input(shape=input_shape)\n","  x = keras.layers.Dense(256, activation='relu')(inputs)\n","  x = keras.layers.Dense(128, activation='relu')(x)\n","  outputs = keras.layers.Dense(num_classes)(x)\n","  return keras.Model(inputs, outputs)    "],"metadata":{"id":"CxqH8nKuRXi2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IN_FTRS = 32 * 32 * 3 # CIFAR-10 images are 32 x 32 and have 3 channels\n","net = get_baby_thanos(input_shape=IN_FTRS, num_classes=10)"],"metadata":{"id":"O-dwbekbT49S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net.summary()"],"metadata":{"id":"P4L8u-SMgIrN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Flatten Images"],"metadata":{"id":"fBfLVjhvPX1Z"}},{"cell_type":"code","source":["train_images = train_images.reshape(-1, IN_FTRS)\n","test_images = test_images.reshape(-1, IN_FTRS)"],"metadata":{"id":"hiak5YcSPXDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_images.shape, test_images.shape)"],"metadata":{"id":"Z8UwzM2cPpqU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **YOUR EXERCISE HERE: Hyperparameters to tune** ðŸ‘‡\n","While there are a ton of hyperparameters that we can play with, we'll focus on the three most commonly tuned ones:\n","- Epochs : Number of times the model sees the entire dataset\n","- Batch Size: How many examples of the dataset the model sees at a time\n","- Learning Rate: How much the gradients affect the weights (See the optimizer call below)\n","\n","Change these values one at a time and observe how the training curves change. As a suggestion, play with the learning rate first and then try changing the batch size and then the number of epochs. How does the model's performances change?"],"metadata":{"id":"pp6XaQY8R90J"}},{"cell_type":"code","source":["LEARNING_RATE = 0.001\n","EPOCHS = 20\n","BATCH_SIZE = 64"],"metadata":{"id":"ecsRzyp7R_ve"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Optimizer & Loss Function\n","These two functions allow us to help baby thanos learn from his mistakes."],"metadata":{"id":"KL_5TfglTy3D"}},{"cell_type":"code","source":["criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True) # Loss Function\n","optimizer = keras.optimizers.SGD(learning_rate=LEARNING_RATE) # Optimizer "],"metadata":{"id":"Hnj1-mPITxjE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train and Evaluate the Network\n","The training and validation loops call the same set of functions over and over. Keras packages them into a nice function called `fit()` which does a lot more :)"],"metadata":{"id":"b13gdPYtUBmF"}},{"cell_type":"code","source":["net.compile(\n","    optimizer=optimizer,\n","    loss=criterion,\n","    metrics=[\"accuracy\"],\n",")"],"metadata":{"id":"_bvQQNXYV6yu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = net.fit(train_images, \n","                  y_train, \n","                  batch_size=BATCH_SIZE,\n","                  epochs=EPOCHS, \n","                  validation_data=(test_images, y_test),\n","                  )"],"metadata":{"id":"nwIv6azQOdYq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot the Loss and Accuracy of our Model"],"metadata":{"id":"ym8N-On3AABv"}},{"cell_type":"code","source":["plt.figure(figsize=(8,8))\n","plt.plot(history.history[\"loss\"], label=\"train\")\n","plt.plot(history.history[\"val_loss\"], label=\"val\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","plt.grid(\"on\")\n","plt.legend()\n","plt.title(\"Loss vs Epochs\");"],"metadata":{"id":"9S3y9L1L-WCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,8))\n","plt.plot(history.history['accuracy'], label='accuracy')\n","plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.grid(\"on\")\n","plt.legend()\n","plt.title(\"Accuracy vs Epochs\");"],"metadata":{"id":"MaZ5ZfTu_TfI"},"execution_count":null,"outputs":[]}]}
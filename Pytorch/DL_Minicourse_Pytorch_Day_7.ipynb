{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1d_dvfuNRg8OlruyAGZEyfSLvxtRdLrC8","timestamp":1665208555188},{"file_id":"1u_k6LDv44r1t92PBpgiA1Ll4aGn9xpeu","timestamp":1665208225948},{"file_id":"1DfmuC_ClBQlwo5LztUEtFTA391m4JnLp","timestamp":1665206617341},{"file_id":"1b52y2OosIWkdyNVqITs-LKCxjkR_1GHM","timestamp":1665205349714},{"file_id":"19OqQ7FR1IBbmN1lS-BsCwHKdEV0LcVsa","timestamp":1665203799318},{"file_id":"1MeWh78fXU0GbNwbw2uTJySmfvw1KWjKq","timestamp":1665103902452},{"file_id":"1pwiOBgRVAgW7KGVFdJWdTTamlQ7bfUXe","timestamp":1665103747612}],"collapsed_sections":[],"authorship_tag":"ABX9TyNGg2b/RGxw6YKZHy8gg3iM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/ssundar6087/Deep-Learning-Mini-Course/blob/main/Pytorch/DL_Minicourse_Pytorch_Day_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"],"metadata":{"id":"bvkmIxUquAfO"}},{"cell_type":"markdown","source":["# It's the final countdown!\n","Today, we'll wrap up the course by implementing checkpointing, early stopping and trying out some transfer learning. Congratulations on making it so far! ðŸ™Œ"],"metadata":{"id":"e--Ti2Ov8GTm"}},{"cell_type":"markdown","source":["# Image Classification Pytorch"],"metadata":{"id":"tGV5DlzgRFNK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJmKqClAQ4x9"},"outputs":[],"source":["# Imports\n","import torch \n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"markdown","source":["## Model Definition\n","Replace the definition below with your best conv net from the previous exercise"],"metadata":{"id":"SMBKXZyURnyE"}},{"cell_type":"code","source":["class BabyThanos(nn.Module):\n","  def __init__(self, in_dims, in_channels, n_classes=10):\n","    super().__init__()\n","    \n","    self.in_dims = in_dims \n","    self.in_channels = in_channels\n","    self.n_classes = n_classes\n","    self.k = 5\n","    self.n_filters1 = 6\n","    self.n_filters2 = 16\n","    self.fc1_dim = 100\n","    self.fc2_dim = 40\n","    self.pool_size = 2\n","    self.pool_stride = 2\n","    self.final_dim = self.__compute_flattened_dim__(num_conv_pools=2)\n","\n","    # define the layers here\n","    self.conv1 = nn.Conv2d(self.in_channels, self.n_filters1, self.k)\n","    self.pool = nn.MaxPool2d(self.pool_size, self.pool_stride)\n","    self.conv2 = nn.Conv2d(self.n_filters1, self.n_filters2, self.k)\n","    self.fc1 = nn.Linear(self.n_filters2 * self.final_dim * self.final_dim, self.fc1_dim)\n","    self.fc2 = nn.Linear(self.fc1_dim, self.fc2_dim)\n","    self.fc3 = nn.Linear(self.fc2_dim, self.n_classes)\n","\n","\n","  def __compute_flattened_dim__(self, num_conv_pools):\n","    final_dim = self.in_dims\n","    for i in range(num_conv_pools):\n","      final_dim = (final_dim + 0 - self.k) // 1 + 1\n","      final_dim = final_dim // self.pool_size\n","    return final_dim\n","\n","  def forward(self, x):\n","      x = self.conv1(x)\n","      x = F.relu(x) \n","      x = self.pool(x)\n","      x = self.conv2(x)\n","      x = F.relu(x) \n","      x = self.pool(x)\n","      x = torch.flatten(x, 1) \n","      x = F.relu(self.fc1(x)) \n","      x = F.relu(self.fc2(x)) \n","      x = self.fc3(x)\n","      return x\n","    "],"metadata":{"id":"CxqH8nKuRXi2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["IN_DIMS = 32 \n","IN_CHANNELS = 3\n","N_CLASSES = 10\n","net = BabyThanos(in_dims=IN_DIMS, in_channels=IN_CHANNELS, n_classes=N_CLASSES)"],"metadata":{"id":"O-dwbekbT49S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(net)"],"metadata":{"id":"P4L8u-SMgIrN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hyperparameters \n","**Note:** Use the best values from the previous exercise"],"metadata":{"id":"bDozysqD6F8c"}},{"cell_type":"code","source":["BATCH_SIZE = 64\n","EPOCHS = 20\n","LEARNING_RATE = 1e-3"],"metadata":{"id":"rf_QykFL6EgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n","                                          shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n","                                         shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"],"metadata":{"id":"4mvlOIOA76Io"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Define Optimizer & Loss Function \n","These two functions allow us to help baby thanos learn from his mistakes.\n","\n","Use the best choices from the previous exercise"],"metadata":{"id":"KL_5TfglTy3D"}},{"cell_type":"code","source":["criterion = nn.CrossEntropyLoss() # Loss Function\n","optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE) # Optimizer "],"metadata":{"id":"Hnj1-mPITxjE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"fpC1vbLuUbHX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Train and Evaluate the Network \n","The training and validation loops call the same set of functions over and over, so we'll package them into separate functions. Note that the validation loop does not have any optimizer calls. "],"metadata":{"id":"b13gdPYtUBmF"}},{"cell_type":"code","source":["from tqdm.notebook import tqdm\n","def train_step(model, train_loader, optimizer, criterion):\n","  model.train()\n","  epoch_loss = []\n","  total, correct = 0, 0\n","\n","  for i, batch in tqdm(enumerate(train_loader), \n","                       total=len(train_loader),\n","                       leave=False,\n","                       ):\n","    images, labels = batch\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    optimizer.zero_grad() # Erase history - clean slate\n","\n","    predictions = model(images) # forward -> model (images) -> make guesses on labels\n","    loss = criterion(predictions, labels) # how did I do?\n","    epoch_loss.append(loss.item())\n","    _, predicted = torch.max(predictions.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item() # Accuracy score\n","    loss.backward() # backward pass\n","    optimizer.step() # Update the weights using gradients\n","\n","  \n","  return np.mean(epoch_loss), correct / total\n"],"metadata":{"id":"oT7wrZHVT8z9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def valid_step(model, val_loader, criterion):\n","  model.eval()\n","  epoch_loss = []\n","  total, correct = 0, 0\n","\n","  with torch.no_grad():\n","    for i, batch in tqdm(enumerate(val_loader), \n","                        total=len(val_loader),\n","                        leave=False,\n","                        ):\n","      images, labels = batch\n","      images = images.to(device)\n","      labels = labels.to(device)\n","      # Note that there's no optimizer here\n","      predictions = model(images)\n","      loss = criterion(predictions, labels)\n","      epoch_loss.append(loss.item())\n","      _, predicted = torch.max(predictions.data, 1)\n","      total += labels.size(0)\n","      correct += (predicted == labels).sum().item()\n","  \n","  return np.mean(epoch_loss), correct / total"],"metadata":{"id":"2GkxuVRVVm-B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" ## **YOUR EXERCISE HERE: Checkpointing and Early Stopping ðŸ‘‡** \n","\n"," Implement early stopping and checkpointing below. If you are stuck, check out these hints\n","\n"," **HINT:** https://github.com/Bjarten/early-stopping-pytorch/blob/master/pytorchtools.py and https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html"],"metadata":{"id":"IlxISOzINroe"}},{"cell_type":"code","source":["net = net.to(device)\n","losses = {\"train_loss\": [], \"val_loss\": []}\n","accuracies = {\"train_acc\": [], \"val_acc\": []}\n","epochs = []\n","for epoch in tqdm(range(EPOCHS), total=EPOCHS):\n","  train_loss, train_acc = train_step(net, \n","                                     trainloader, \n","                                     optimizer, \n","                                     criterion,)\n","  \n","  val_loss, val_acc = valid_step(net, \n","                                 testloader, \n","                                 criterion,\n","                                 )\n","  \n","  #TODO: YOUR CODE HERE -\n","  # 1. Checkpoint the model \n","\n","  # 2. Check for Early Stopping\n","  \n","  # END OF YOUR CODE\n","  \n","  losses[\"train_loss\"].append(train_loss)\n","  losses[\"val_loss\"].append(val_loss)\n","  accuracies[\"train_acc\"].append(train_acc)\n","  accuracies[\"val_acc\"].append(val_acc)\n","  epochs.append(epoch)\n","\n","  print(f'[{epoch + 1}] train loss: {train_loss}  train accuracy: {train_acc}  val loss: {val_loss}  val accuracy: {val_acc}')"],"metadata":{"id":"_bvQQNXYV6yu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Plot the Loss and Accuracy of our Model"],"metadata":{"id":"ym8N-On3AABv"}},{"cell_type":"code","source":["plt.figure(figsize=(8,8))\n","plt.plot(epochs, losses[\"train_loss\"], label=\"train\")\n","plt.plot(epochs, losses[\"val_loss\"], label=\"val\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","plt.grid(\"on\")\n","plt.legend()\n","plt.title(\"Loss vs Epochs\")"],"metadata":{"id":"9S3y9L1L-WCc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,8))\n","plt.plot(epochs, accuracies[\"train_acc\"], label=\"train\")\n","plt.plot(epochs, accuracies[\"val_acc\"], label=\"val\")\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"accuracy\")\n","plt.grid(\"on\")\n","plt.legend()\n","plt.title(\"Accuracy vs Epochs\")"],"metadata":{"id":"MaZ5ZfTu_TfI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **YOUR EXERCISE HERE: Transfer Learning ðŸ‘‡** \n","\n","Repeat the same exercise but swap out the model definition with this one first\n","\n","Try out other models from here https://pytorch.org/vision/stable/models.html"],"metadata":{"id":"v9yOvR3cNL7w"}},{"cell_type":"code","source":["class ThanosWithInfinityStones(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.backbone = torchvision.models.resnet18(pretrained=True)\n","    num_ftrs = self.backbone.fc.in_features # model = models.resnet18() print(model)\n","    self.fc1_dim = 128\n","    self.backbone.fc = nn.Linear(num_ftrs, self.fc1_dim)\n","    self.clf_head = nn.Linear(self.fc1_dim, len(classes))\n","  \n","  def forward(self, x):\n","    x = self.backbone(x)\n","    x = self.clf_head(F.relu(x)) # (batch_size, num_classes)\n","    return x"],"metadata":{"id":"uDtUgcJQNTpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["net = ThanosWithInfinityStones()"],"metadata":{"id":"CNrCmPqhNjhb"},"execution_count":null,"outputs":[]}]}